## 实验环境：
### 硬件环境
### 软件环境
## 实验设置
### 保真度实验：
> 基于CIFAR-10数据集，Non-IID分布，标签偏移为4，100个client,保证每个client数据大小相同。从中抽取10,15,20个client,做水印嵌入，每轮只有这些client参与训练。
  + 加入/不加入水印时的精度对比 [FedIPR PFLIPR] 
    + 保证每个client数据大小相同 
  + 固定水印bit数，改变人数     [FedIPR PFLIPR]
  + 固定人数，改变水印bit数     [FedIPR PFLIPR]
### 检测率实验：
> 基于CIFAR-10数据集，Non-IID分布，标签偏移为4，100个client,保证每个client数据大小相同。从中抽取10,15,20个client,做水印嵌入，每轮只有这些client参与训练。
  + 交给别人检测时，能不能检测出来 [FedIPR PFLIPR]
    + 每行一致的
  + 对比存在全局模型聚合操作的水印方案 [FedIPR PFLIPR]
  + 不同人数，不同bit长度的检测率对比 [FedIPR PFLIPR]
### 攻击实验
> 基于CIFAR-10数据集，将保存的水印，模型，head读入。进行剪枝。
  + 对head进行剪枝 [FedIPR PFLIPR]
  + 对模型进行微调 [FedIPR PFLIPR]


## 改进方案
+ 调整水印层数，增加head层数
  + 水印的效果可能和嵌入参数的数目有关，所以可以考虑增加水印层数
## 下一步工作
+ Noniid 代码
  + label10的情况下正常，证明代码没问题。在label2的情况下，acc下降，是正常的。
+ 整理对比
+ 改进pflipr
    + head 嵌入方式,三层。
    + 内存不够，保存读取。

## 论文阅读：
+ Embedding Watermarks into Deep Neural Networks
+ Exploiting Shared Representations for Personalized Federated Learning
  + 实验是基于以上两篇论文的代码做的
+ FedIPR: Ownership Verification for Federated Deep Neural Network Models
  + 对比论文
+ DeepIPR: Deep Neural Network Ownership Verification With Passports
  + 混淆攻击，后面看能不能抵御

## 实验参数确定

--dataset cifar10 
--model cnn 
--num_classes 10 
--epochs 100 
--alg fedrep 
--lr 0.01
--num_users 100 
--gpu 0 
--shard_per_user 2 
--test_freq 1
--local_ep 11 
--frac 0.1 
--local_rep_ep 1 
--local_bs 10

改变的参数
--use_watermark [True,False]
--embed_dim [64,128,192,256,320,384,448]
--scale 0.1
--frac [0.1,0.2,0.3]

**ck: noniid 参数**

  -- datadir 数据文件夹
  -- beta  dirichlet distribution分布参数
  -- num_classes 作废,partition_data 会根据数据集确定
  -- partition 划分的形式 (homo noniid-labeldir noniid-#label iid-diff-quantity mixed)

## 实验问题：

#### noniid 修改后acc大幅下降

解决: 划分函数是随机划分标签，一个client的训练集和测试集应该是同种标签分配。修改划分函数，同时返回训练集和测试集的划分。

#### 剪枝方法

在 Torch 中，`torch.nn.utils.prune` 模块提供了多种剪枝方法和功能。以下是这个模块中常用的剪枝函数：

1. `torch.nn.utils.prune.ln_structured(x, name=None, amount=0.5, n=2, dim=0)`: L_n结构化剪枝。将维度dim的所有元素L_n标准化后按比例amount删除最小的n%。

2. `torch.nn.utils.prune.random_unstructured(x, name=None, amount=0.5)`: 随机剪枝。随机删除给定张量x中具有较小幅值的参数。

3. `torch.nn.utils.prune.l1_unstructured(x, name=None, amount=0.5)`: L1非结构化剪枝。按比例amount删除x中绝对值最小的参数。


4. `torch.nn.utils.prune.global_unstructured(x, pruning_fn, parameters, default=None)`: 全局非结构剪枝。将x中所有元素应用pruning_fn函数，该函数采用当前参数和default作为输入。

5. `torch.nn.utils.prune.remove(module, name)`: 移除指定名称的剪枝参数。

#### epochs=50/100 剪枝的效果不变

head 没有区分epochs，所以剪枝的时候，不管是50还是100，都是一样的

#### clients抽样问题

FedIPR采用的是不抽样，每轮只训练指定的clients。这样便于验证水印。
因为水印问题是考虑对参与模型训练的clients进行产权保护，所以可以只关注参与的clients
可以尝试这样，frac为1，num_user为10。

#### 水印嵌入数目
所有用户的水印应该不超过所有嵌入的参数数目

#### 对于水印嵌入的修改思路

参考FedIPR

1. head头的选择对模型的影响 ?
  - 对于图像分类问题，卷积层应该是公用的。所以只能考虑在线形层来做。
2. 假定嵌入水印长度为bits,对于要嵌入的每层，按照比例计算每层嵌入的数目。

#### 对比实验

将FedIPR的方法迁移到pflipr中，发现修改过的conv层输出为[10,64,6,6]和原来的[10,64,5,5]不同。没有找到原因，这里将线形层的输入由[64x5x5]改为[64x6x6]

#### 迁移CNN模型，模型太简单了，不能很好的对比出实验效果

将pflipr的模型修改为fedipr的模型，但是简单的cnn通道数和参数太少了，实验效果可能不太明显。

#### 水印嵌入方式，所有参数展开的矩阵太大了，内存不够用